{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I am going to check if (some of) the HD direction cells are actually moving direction cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import convolve1d\n",
    "from numpy import deg2rad\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.interpolate import interp1d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(ratname, file_path):\n",
    "    # Load the .mat file\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # List all keys\n",
    "        keys = list(f.keys())\n",
    "        #print(f\"Keys: {keys}\")\n",
    "\n",
    "        # Access the sdata structure\n",
    "        sdata = f['sdata']\n",
    "\n",
    "        # Check if 'light1' exists in sdata\n",
    "        if 'light1' not in sdata:\n",
    "            print(f\"'light1' not found in {file_path}\")\n",
    "            return None\n",
    "\n",
    "        # Accessing the light1 group and its datasets\n",
    "        light1 = sdata['light1']\n",
    "        ppox = np.array(light1['pox'])\n",
    "        ppoy = np.array(light1['poy'])\n",
    "        pot = np.array(light1['pot'])\n",
    "        poh = np.array(light1['poh'])\n",
    "        pov = np.array(light1['pov'])\n",
    "        f0 = np.array(light1['F0'])\n",
    "        sintcptFreqy = np.array(light1['sintcptFreqy'])\n",
    "\n",
    "        # Extract all cells containing the name 'R222'\n",
    "        cell_names = [key for key in sdata.keys() if ratname in key]\n",
    "        #print(f\"Cell Names: {cell_names}\")\n",
    "\n",
    "        # Initialize dictionary to store data for all cells\n",
    "        cells_data = {}\n",
    "\n",
    "        # Iterate over each cell name and extract data\n",
    "        for cell_name in cell_names:\n",
    "            part_now = 'light1'  # Assuming 'light1' is the part_now equivalent\n",
    "\n",
    "            pspx = np.array(sdata[cell_name][part_now]['spx'])\n",
    "            pspy = np.array(sdata[cell_name][part_now]['spy'])\n",
    "            pspt = np.array(sdata[cell_name][part_now]['spt'])\n",
    "            pspv = np.array(sdata[cell_name][part_now]['spv'])\n",
    "            psph = np.array(sdata[cell_name][part_now]['sph'])\n",
    "            pspm = np.array(sdata[cell_name][part_now]['spm'])\n",
    "            pval = np.array(sdata[cell_name][part_now]['pval'])\n",
    "            spike_phase = np.array(sdata[cell_name][part_now]['spike_phase'])\n",
    "            autocorrelogram = np.array(sdata[cell_name][part_now]['theta_train_long2'])\n",
    "            hd_mean = np.array(sdata[cell_name][part_now]['hd_mean'])\n",
    "            hd_std = np.array(sdata[cell_name][part_now]['hd_stdev'])\n",
    "            tune_width = np.array(sdata[cell_name][part_now]['tuning_width'])\n",
    "            intrinsic_freq = np.array(sdata[cell_name][part_now]['intrinsic_theta_frequency'])\n",
    "\n",
    "            # Extract and decode cell_type\n",
    "            cell_type_array = np.array(sdata[cell_name][part_now]['thetacell_type'])\n",
    "            cell_type = ''.join([chr(ascii_val[0]) for ascii_val in cell_type_array])\n",
    "\n",
    "            # Store the data for this cell\n",
    "            cells_data[cell_name] = {\n",
    "                'pspx': pspx,\n",
    "                'pspy': pspy,\n",
    "                'pspt': pspt,\n",
    "                'pspv': pspv,\n",
    "                'psph': psph,\n",
    "                'pspm': pspm,\n",
    "                'pval': pval,\n",
    "                'spike_phase': spike_phase,\n",
    "                'autocorrelogram': autocorrelogram,\n",
    "                'hd_mean': hd_mean,\n",
    "                'hd_std': hd_std,\n",
    "                'tune_width': tune_width,\n",
    "                'intrinsic_freq': intrinsic_freq,\n",
    "                'cell_type': cell_type\n",
    "            }\n",
    "\n",
    "        # Create a dictionary to store all the data\n",
    "        data_dict = {\n",
    "            'ppox': ppox,\n",
    "            'ppoy': ppoy,\n",
    "            'pot': pot,\n",
    "            'poh': poh,\n",
    "            'pov': pov,\n",
    "            'f0': f0,\n",
    "            'sintcptFreqy': sintcptFreqy,\n",
    "            'cell_names': cell_names,\n",
    "            'cells_data': cells_data\n",
    "        }\n",
    "\n",
    "        return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angular_speed(poh, pot, sigma=5):\n",
    "    \"\"\"\n",
    "    Calculate the head rotation speed (angular speed) from head direction and time data.\n",
    "\n",
    "    Parameters:\n",
    "    poh : np.array\n",
    "        Array of head direction angles in degrees.\n",
    "    pot : np.array\n",
    "        Array of time points corresponding to the head direction angles.\n",
    "    sigma : float\n",
    "        Standard deviation for Gaussian kernel used in smoothing.\n",
    "\n",
    "    Returns:\n",
    "    angular_speed : np.array\n",
    "        Array of angular speed values.\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure head direction angles are in radians\n",
    "    poh_rad = np.deg2rad(poh)\n",
    "\n",
    "    # Convert angles to complex exponential form\n",
    "    poh_complex = np.exp(1j * poh_rad)\n",
    "\n",
    "    # Apply Gaussian smoothing to real and imaginary parts separately\n",
    "    poh_smooth_real = gaussian_filter1d(poh_complex.real, sigma=sigma)\n",
    "    poh_smooth_imag = gaussian_filter1d(poh_complex.imag, sigma=sigma)\n",
    "\n",
    "    # Convert back to angles\n",
    "    poh_smooth = np.angle(poh_smooth_real + 1j * poh_smooth_imag)\n",
    "\n",
    "    # Calculate the time differences\n",
    "    dt = np.diff(pot)\n",
    "\n",
    "    # Calculate the angle differences\n",
    "    dtheta = np.diff(poh_smooth)\n",
    "    \n",
    "    #deal with the jump between 0 and 2pi\n",
    "    dtheta[dtheta > np.pi] -= 2 * np.pi\n",
    "    dtheta[dtheta < -np.pi] += 2 * np.pi\n",
    "    \n",
    "    # Calculate the angular speed\n",
    "    angular_speed = dtheta / dt\n",
    "    \n",
    "    angular_speed = angular_speed.flatten()\n",
    "\n",
    "    #add one element to the beginning of angular_speed to make it the same length as poh\n",
    "    angular_speed = np.insert(angular_speed, 0, angular_speed[0])\n",
    "\n",
    "    return angular_speed\n",
    "\n",
    "def get_angular_speed_at_spikes(pspt, pot, angular_speed):\n",
    "\n",
    "    angular_speed_spike = []\n",
    "    for spike_time in pspt:\n",
    "        # Find the index of the closest time in pot\n",
    "        index = np.argmin(np.abs(pot - spike_time))\n",
    "        angular_speed_spike.append(angular_speed[index])\n",
    "    \n",
    "    return np.array(angular_speed_spike)\n",
    "\n",
    "def find_continuous_periods(angular_speed, pot, speed_threshold=0.5, duration_threshold=1.0):\n",
    "    if speed_threshold > 0:\n",
    "        # Identify where angular speed exceeds the threshold\n",
    "        above_threshold = angular_speed > speed_threshold\n",
    "    elif speed_threshold < 0:\n",
    "        # Identify where angular speed is below the threshold\n",
    "        above_threshold = angular_speed < speed_threshold\n",
    "    else:\n",
    "        raise ValueError(\"Speed threshold must be non-zero\")\n",
    "\n",
    "    # Find the indices where the state changes\n",
    "    change_indices = np.diff(above_threshold.astype(int), prepend=0, append=0)\n",
    "\n",
    "    # Identify the start and end indices of the segments\n",
    "    start_indices = np.where(change_indices == 1)[0]\n",
    "    end_indices = np.where(change_indices == -1)[0]\n",
    "\n",
    "    # Ensure there is a matching number of start and end indices\n",
    "    if len(start_indices) > len(end_indices):\n",
    "        end_indices = np.append(end_indices, len(angular_speed) - 1)\n",
    "    elif len(end_indices) > len(start_indices):\n",
    "        start_indices = np.insert(start_indices, 0, 0)\n",
    "\n",
    "    continuous_periods = []\n",
    "    for start, end in zip(start_indices, end_indices):\n",
    "        if end >= len(pot):\n",
    "            end = len(pot) - 1\n",
    "        duration = pot[end] - pot[start]\n",
    "        if duration >= duration_threshold:\n",
    "            continuous_periods.append((pot[start], pot[end]))\n",
    "\n",
    "    return continuous_periods\n",
    "\n",
    "def compute_spike_array(spike_times, timestamps):\n",
    "    \"\"\"\n",
    "    Compute the spike array from spike times and timestamps.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Assume t is sorted. If not, you must sort it first.\n",
    "    indices = np.searchsorted(timestamps, spike_times, side='right')\n",
    "\n",
    "    # Ensure no out-of-bounds indices\n",
    "    indices = np.clip(indices, 0, len(timestamps) - 1)\n",
    "\n",
    "    # Adjust indices to always refer to the nearest timestamp\n",
    "    # If the index points to the start of the array, no need to adjust\n",
    "    # If not, check if the previous index is closer\n",
    "    prev_close = (indices > 0) & (np.abs(timestamps[indices - 1] - spike_times) < np.abs(timestamps[indices] - spike_times))\n",
    "    indices[prev_close] -= 1\n",
    "\n",
    "    spike_array = np.zeros_like(timestamps)\n",
    "    np.add.at(spike_array, indices, 1) #very fast!\n",
    "    \n",
    "    return spike_array\n",
    "\n",
    "def calculate_intrinsic_frequency(autocorrelogram):\n",
    "    def model(t, a, b, c, omega, t1, t2):\n",
    "        return (a * (np.sin(2*np.pi*omega * t) + 1) + b) * np.exp(-np.abs(t) / t1) + c * np.exp(-t**2 / t2**2)\n",
    "    \n",
    "    # Fit the model to the autocorrelogram data\n",
    "    initial_guess = [1, 0.1, 0.1, 8, 0.01, 0.01]  # Initial guesses for a, b, c, omega, t1, t2\n",
    "    bounds = ([0, 0, 0, 6, 0, 0], [np.inf, np.inf, 0.8, 12, 0.05, 0.05])  # Bounds for the parameters\n",
    "\n",
    "    autocorr = autocorrelogram[0, :]\n",
    "    lags = autocorrelogram[1, :] / 1000  # Convert lags to seconds\n",
    "\n",
    "    params, covariance = curve_fit(model, lags, autocorr, p0=initial_guess, bounds=bounds)\n",
    "    # Extract the intrinsic frequency (omega)\n",
    "    intrinsic_frequency = params[3]\n",
    "    print(f\"Intrinsic Theta Frequency: {intrinsic_frequency:.2f} Hz\")\n",
    "    \n",
    "    return intrinsic_frequency  \n",
    "\n",
    "def compute_autocorrelation(spike_array, bin_size=0.02, max_lag=0.5):\n",
    "    # Number of bins for the max_lag\n",
    "    max_lag_bins = int(max_lag / bin_size)\n",
    "    autocorr = np.correlate(spike_array, spike_array, mode='full')\n",
    "    mid_point = len(autocorr) // 2\n",
    "    autocorr = autocorr[mid_point - max_lag_bins: mid_point + max_lag_bins + 1]\n",
    "    \n",
    "    # Normalize the autocorrelation values\n",
    "    lags = np.arange(-max_lag_bins, max_lag_bins + 1) * bin_size  # Lags in seconds\n",
    "    \n",
    "    idx_range = np.where((lags >= 0.05) & (lags <= 0.25))[0]\n",
    "    max_value = np.max(autocorr[idx_range])\n",
    "    autocorr = autocorr / max_value\n",
    "    autocorr = np.clip(autocorr, a_min=None, a_max=1)  # Clip values above 1\n",
    "    \n",
    "    lags_ms = lags * 1000  # Convert to ms\n",
    "    \n",
    "    # Convert autocorr, lags into a 2*n array\n",
    "    return np.array([autocorr, lags_ms])\n",
    "\n",
    "def get_autocorrelogram_move_still(ppoh, pot, pspt, config):\n",
    "\n",
    "    speed_threshold = config['speed_threshold']\n",
    "    duration_threshold = config['duration_threshold']\n",
    "    speed_smooth_sigma = config['speed_smooth_sigma']\n",
    "\n",
    "    #calculate angular speed\n",
    "    angular_speed = calculate_angular_speed(ppoh, pot, sigma=speed_smooth_sigma)\n",
    "\n",
    "    continuous_periods_CCW = find_continuous_periods(angular_speed, pot, speed_threshold=-speed_threshold, duration_threshold=duration_threshold)\n",
    "    continuous_periods_CW = find_continuous_periods(angular_speed, pot, speed_threshold=speed_threshold, duration_threshold=duration_threshold)\n",
    "\n",
    "    pspt_move = []\n",
    "    for i in range(len(continuous_periods_CCW)):\n",
    "        #keet pspt if it is in the continuous period\n",
    "        pspt_move.extend(pspt[(pspt >= continuous_periods_CCW[i][0]) & (pspt <= continuous_periods_CCW[i][1])])\n",
    "    for i in range(len(continuous_periods_CW)):\n",
    "        #keet pspt if it is in the continuous period\n",
    "        pspt_move.extend(pspt[(pspt >= continuous_periods_CW[i][0]) & (pspt <= continuous_periods_CW[i][1])])    \n",
    "\n",
    "    #sort\n",
    "    pspt_move = np.sort(pspt_move)\n",
    "\n",
    "    spike_array = compute_spike_array(pspt_move, pot)\n",
    "    autocorrelogram_move = compute_autocorrelation(spike_array, bin_size=0.02, max_lag=0.5) \n",
    "\n",
    "    #get remaining spike time\n",
    "    pspt_rest = np.setdiff1d(pspt, pspt_move)\n",
    "    spike_array = compute_spike_array(pspt_rest, pot)\n",
    "    autocorrelogram_still = compute_autocorrelation(spike_array, bin_size=0.02, max_lag=0.5)\n",
    "\n",
    "    return autocorrelogram_move, autocorrelogram_still\n",
    "\n",
    "\n",
    "def compute_moving_direction(ppox, ppoy, pot, ppoh, temporal_smooth_sigma=5):\n",
    "    \"\"\"\n",
    "    Calculate the moving direction based on position data and temporal smoothing.\n",
    "    \n",
    "    Parameters:\n",
    "    ppox : np.array\n",
    "        Array of x positions.\n",
    "    ppoy : np.array\n",
    "        Array of y positions.\n",
    "    pot : np.array\n",
    "        Array of time points.\n",
    "    temporal_smooth_sigma : float\n",
    "        Standard deviation for Gaussian kernel used in smoothing.\n",
    "        \n",
    "    Returns:\n",
    "    moving_direction : np.array\n",
    "        Array of moving direction angles in degrees.\n",
    "    \"\"\"\n",
    "    ppoh = ppoh.flatten()\n",
    "    # Convert int16 to float\n",
    "    ppox = ppox.astype(float)\n",
    "    ppoy = ppoy.astype(float)\n",
    "    \n",
    "    # Apply Gaussian smoothing to position data\n",
    "    ppox_smooth = gaussian_filter1d(ppox, sigma=temporal_smooth_sigma)\n",
    "    ppoy_smooth = gaussian_filter1d(ppoy, sigma=temporal_smooth_sigma)\n",
    "    \n",
    "    # Calculate the differences\n",
    "    dx = np.diff(ppox_smooth)\n",
    "    dy = np.diff(ppoy_smooth)\n",
    "    \n",
    "    # Identify non-movement periods (where both dx and dy are zero)\n",
    "    # moving_mask = (dx != 0) | (dy != 0)\n",
    "    \n",
    "    # print(moving_mask.shape[0], sum(moving_mask))\n",
    "    \n",
    "    # Calculate the moving direction in radians for moving periods\n",
    "    moving_direction_rad = np.arctan2(dy, dx)\n",
    "    \n",
    "    # Convert to degrees\n",
    "    moving_direction_deg = np.rad2deg(moving_direction_rad)\n",
    "    \n",
    "    # Adjust to range 0-360 degrees\n",
    "    moving_direction_deg = np.mod(moving_direction_deg, 360)\n",
    "    \n",
    "    # # Interpolate to fill in non-movement periods\n",
    "    # full_pot = pot[:-1]  # Exclude the last point to match the length of dx, dy\n",
    "    # interpolator = interp1d(full_pot[moving_mask], moving_direction_deg, kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "    # moving_direction_full = interpolator(full_pot)\n",
    "    \n",
    "    # # Ensure moving_direction_full has the same length as pot by padding the end\n",
    "    # moving_direction_full = np.append(moving_direction_full, moving_direction_full[-1])\n",
    "    moving_direction_full = np.append(moving_direction_deg, moving_direction_deg[-1])\n",
    "    \n",
    "    #now work out the constant offset between the moving direction and the head direction \n",
    "    #and align moving_direction_full to head direction\n",
    "    all_offset = ppoh - moving_direction_full\n",
    "    #deal with the jump between 0 and 2pi\n",
    "    all_offset[all_offset > 300] -= 360\n",
    "    all_offset[all_offset < -300] += 360\n",
    "    offset_mean = np.mean(all_offset)\n",
    "    offset_std = np.std(all_offset)\n",
    "    print(f\"Offset between moving direction and head direction: {offset_mean:.2f} +- {offset_std:.2f} degrees\")\n",
    "    # moving_direction_full += offset\n",
    "    \n",
    "    # #check the offset again\n",
    "    # all_offset = ppoh - moving_direction_full\n",
    "    # #deal with the jump between 0 and 2pi\n",
    "    # all_offset[all_offset > 180] -= 360\n",
    "    # all_offset[all_offset < -180] += 360\n",
    "    # offset = np.mean(all_offset)\n",
    "    # print(f\"Offset between moving direction and head direction after alignment: {offset:.2f} degrees\")\n",
    "    return moving_direction_full\n",
    "\n",
    "def get_spike_direction(ppom, pot, pspt):\n",
    "    \"\"\"\n",
    "    Get the moving direction for each spike event based on the closest time in pot.\n",
    "    \n",
    "    Parameters:\n",
    "    ppom : np.array\n",
    "        Array of moving direction angles in degrees.\n",
    "    pot : np.array\n",
    "        Array of time points corresponding to the moving direction.\n",
    "    pspt : np.array\n",
    "        Array of spike event times.\n",
    "        \n",
    "    Returns:\n",
    "    spike_directions : np.array\n",
    "        Array of moving direction angles at the spike event times.\n",
    "    \"\"\"\n",
    "    spike_directions = []\n",
    "    for spike_time in pspt:\n",
    "        closest_time_idx = np.argmin(np.abs(pot - spike_time))\n",
    "        spike_directions.append(ppom[closest_time_idx])\n",
    "    \n",
    "    return np.array(spike_directions)\n",
    "\n",
    "def get_spike_times_large_diff(ppom, ppoh, pot, pspt, threshold=30):\n",
    "    \"\"\"\n",
    "    Get spike times when the difference between moving direction and head direction is more than a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    ppom : np.array\n",
    "        Array of moving direction angles in degrees.\n",
    "    ppoh : np.array\n",
    "        Array of head direction angles in degrees.\n",
    "    pot : np.array\n",
    "        Array of time points corresponding to the moving direction and head direction.\n",
    "    pspt : np.array\n",
    "        Array of spike event times.\n",
    "    threshold : float\n",
    "        Threshold for the difference in degrees.\n",
    "\n",
    "    Returns:\n",
    "    spike_times_large_diff : np.array\n",
    "        Array of spike times where the difference is more than the threshold.\n",
    "    \"\"\"\n",
    "    ppoh = ppoh.flatten()\n",
    "    \n",
    "    # Compute the difference between ppom and ppoh, considering the circular nature of angles\n",
    "    diff = np.abs(np.mod(ppom - ppoh + 180, 360) - 180)\n",
    "    \n",
    "    # Get the time points where the difference is more than the threshold\n",
    "    large_diff_times = pot[diff > threshold]\n",
    "    \n",
    "    # Find the spike times that are close to these time points\n",
    "    spike_times_large_diff = []\n",
    "    for spike_time in pspt:\n",
    "        closest_time_idx = np.argmin(np.abs(large_diff_times - spike_time))\n",
    "        if np.abs(large_diff_times[closest_time_idx] - spike_time) < np.diff(pot).mean():  # Ensure the time difference is within the sampling interval\n",
    "            spike_times_large_diff.append(spike_time)\n",
    "    \n",
    "    return np.array(spike_times_large_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_head_direction_tuning(ax, ppoh, psph, config, pos_tb=0.02):\n",
    "    \"\"\"\n",
    "    Plot the head direction tuning map in a polar plot.\n",
    "\n",
    "    Parameters:\n",
    "    ax : matplotlib.axes._subplots.PolarAxesSubplot\n",
    "        The polar axes to plot on.\n",
    "    ppoh : np.array\n",
    "        Array of session head direction angles in degrees.\n",
    "    psph : np.array\n",
    "        Array of cell head direction angles in degrees.\n",
    "    pos_tb : float\n",
    "        Time base for converting session HD to time.\n",
    "    cell_name : str\n",
    "        Name of the cell for which the tuning map is plotted.\n",
    "    config : dict\n",
    "        Configuration dictionary containing 'hd_bins' and 'hd_boxcar' parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert angles to radians\n",
    "    ppoh_rad = deg2rad(ppoh)\n",
    "    psph_rad = deg2rad(psph)\n",
    "\n",
    "    # Calculate histograms for session and cell head directions\n",
    "    hd1, _ = np.histogram(ppoh_rad, bins=config['hd_bins'], range=(0, 2 * np.pi))\n",
    "    hd2, _ = np.histogram(psph_rad, bins=config['hd_bins'], range=(0, 2 * np.pi))\n",
    "\n",
    "    # Boxcar filter\n",
    "    boxcar_size = config['hd_boxcar']\n",
    "    boxcar_filter = np.ones(boxcar_size) / boxcar_size\n",
    "\n",
    "    # Apply boxcar filter\n",
    "    hd1_filtered = convolve1d(hd1, boxcar_filter, mode='wrap')\n",
    "    hd2_filtered = convolve1d(hd2, boxcar_filter, mode='wrap')\n",
    "\n",
    "    # Convert session HD to time (i.e., dwelling time in each HD bin)\n",
    "    hd1_time = hd1_filtered * pos_tb\n",
    "\n",
    "    # Calculate HD firing rate\n",
    "    hd3 = hd2_filtered / hd1_time\n",
    "\n",
    "    # Normalize session HD\n",
    "    hd1_normalized = hd1_time / np.max(hd1_time)\n",
    "\n",
    "    # Normalize cell HD firing rate\n",
    "    hd3_normalized = hd3 / np.max(hd3)\n",
    "    hd3_normalized = hd3_normalized.flatten()\n",
    "\n",
    "    # Close the loop by appending the first element to the end\n",
    "    theta = np.linspace(0, 2 * np.pi, config['hd_bins'], endpoint=False)\n",
    "    theta = np.append(theta, theta[0])\n",
    "    hd1_normalized = np.append(hd1_normalized, hd1_normalized[0])\n",
    "    hd3_normalized = np.append(hd3_normalized, hd3_normalized[0])\n",
    "\n",
    "    # Plot the session head direction with shading\n",
    "    ax.plot(theta, hd1_normalized, label='Session Head Direction', color='gray')\n",
    "    ax.fill_between(theta, 0, hd1_normalized, facecolor='gray', alpha=0.2)\n",
    "\n",
    "    # Plot the cell head direction firing rate\n",
    "    ax.plot(theta, hd3_normalized, label='Cell Head Direction Firing Rate', color='#38c7ff')\n",
    "    ax.fill_between(theta, 0, hd3_normalized, facecolor='#38c7ff', alpha=0.5)\n",
    "\n",
    "    #keep 0 90 180 270 as the xticks\n",
    "    ax.set_xticks([0, np.pi / 2, np.pi, 3 * np.pi / 2])\n",
    "    ax.set_xticklabels(['0', '90', '180', '270'])\n",
    "    \n",
    "    #remove yticks\n",
    "    ax.set_yticks([])\n",
    "    \n",
    "    #ax.set_title(cell_name + '\\n'+str(np.round(hd_mean,1))+'('+str(np.round(hd_std,1))+')' +'\\nRayleigh_p=' + str(np.round(pval, 4)), fontsize=10)\n",
    "    \n",
    "    # ax.set_title(f\"{cell_name}\\nAngle:{hd_mean:.0f} ({hd_std:.0f})\\nTuning width:{tune_width:.0f}\\nRayleigh_p={pval:.4f}\", fontsize=10)\n",
    "    # ax.legend()\n",
    "\n",
    "    return ax\n",
    "\n",
    "def plot_autocorrelogram(ax, autocorrelogram, cell_type):\n",
    "    \n",
    "    ax.plot(autocorrelogram[1,:], autocorrelogram[0,:], 'k')\n",
    "    #fillin between y=0 and autocorrelogram\n",
    "    ax.fill_between(autocorrelogram[1,:], 0, autocorrelogram[0,:], facecolor='black')\n",
    "    # ax.set_xticks([-500, 0, 500])\n",
    "    ax.set_yticks([])\n",
    "    # ax.set_xlabel('Lag (ms)')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_title(cell_type)\n",
    "    ax.axis('off')\n",
    "    \n",
    "    #set ylim as np.min(autocorrelogram[0,:]) and np.max(autocorrelogram[0,:])\n",
    "    # ax.set_ylim(np.min(autocorrelogram[0,:]), np.max(autocorrelogram[0,:]))\n",
    "\n",
    "    return ax\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/zilong/Desktop/GridCellThetaSweeps/LomiData/DATA r652/R652_170719_T1_sdata.mat\n",
      "Offset between moving direction and head direction: 16.51 +- 87.18 degrees\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m ppom \u001b[38;5;241m=\u001b[39m compute_moving_direction(ppox, ppoy, pot, ppoh, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovingdirection_sigma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#print(np.min(ppom), np.max(ppom))\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#interpolte pot \u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m sampling_interval \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mdiff(pot)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     60\u001b[0m new_interval \u001b[38;5;241m=\u001b[39m sampling_interval \u001b[38;5;241m/\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolation_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m pot_interp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, pot[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], new_interval)\n",
      "Cell \u001b[0;32mIn[14], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m ppom \u001b[38;5;241m=\u001b[39m compute_moving_direction(ppox, ppoy, pot, ppoh, config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovingdirection_sigma\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m#print(np.min(ppom), np.max(ppom))\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#interpolte pot \u001b[39;00m\n\u001b[0;32m---> 59\u001b[0m sampling_interval \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mdiff(pot)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     60\u001b[0m new_interval \u001b[38;5;241m=\u001b[39m sampling_interval \u001b[38;5;241m/\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterpolation_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m pot_interp \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, pot[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], new_interval)\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/anticipative_track_gpu/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframes_tracker\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[38;5;66;03m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anticipative_track_gpu/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "base_dir = '/home/zilong/Desktop/GridCellThetaSweeps/LomiData/'\n",
    "output_dir = '/home/zilong/Desktop/GridCellThetaSweeps/figures/movingdirection_test/all/'\n",
    "output_skip_dir = '/home/zilong/Desktop/GridCellThetaSweeps/figures/movingdirection_test/skip/'\n",
    "output_nonskip_dir = '/home/zilong/Desktop/GridCellThetaSweeps/figures/movingdirection_test/nonskip/'\n",
    "output_nontheta_dir = '/home/zilong/Desktop/GridCellThetaSweeps/figures/movingdirection_test/nontheta/'\n",
    "\n",
    "# Configuration\n",
    "config = {\n",
    "    'hd_bins': 60,\n",
    "    'hd_boxcar': 3,\n",
    "    'speed_threshold': 0.5,\n",
    "    'duration_threshold': 0.5,\n",
    "    'speed_smooth_sigma': 2, \n",
    "    'movingdirection_sigma': 100, #time bin size 20 ms, so 5 is 100 ms\n",
    "    'interpolation_factor': 2 #1 is 0.02s, and 2 is 0.01s\n",
    "}\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "for dir_path in [output_dir, output_skip_dir, output_nonskip_dir, output_nontheta_dir]:\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)    \n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "total_cells = 0\n",
    "\n",
    "all_tw = []\n",
    "nontheta_tw = []\n",
    "theta_tw = []\n",
    "theta_nonskip_tw = []\n",
    "theta_skip_tw = []\n",
    "\n",
    "matnames = {}\n",
    "\n",
    "# Iterate through each subfolder in the base directory\n",
    "for subdir in os.listdir(base_dir):\n",
    "    subdir_path = os.path.join(base_dir, subdir)\n",
    "    if os.path.isdir(subdir_path):\n",
    "        # Iterate through each .mat file in the subfolder\n",
    "        for file in os.listdir(subdir_path):\n",
    "            if file.endswith('_sdata.mat'):\n",
    "                file_path = os.path.join(subdir_path, file)\n",
    "                print(f\"Processing {file_path}\")\n",
    "                ratname = file.split('_')[0]\n",
    "                data_dict = load_data(ratname, file_path)\n",
    "                \n",
    "                if data_dict is not None:\n",
    "                    ppoh = data_dict['poh']\n",
    "                    pot = data_dict['pot'].flatten()\n",
    "                    pov = data_dict['pov'].flatten()\n",
    "                    ppox = data_dict['ppox'].flatten()\n",
    "                    ppoy = data_dict['ppoy'].flatten()\n",
    "                    \n",
    "                    ppom = compute_moving_direction(ppox, ppoy, pot, ppoh, config['movingdirection_sigma'])\n",
    "                    #print(np.min(ppom), np.max(ppom))\n",
    "                    #interpolte pot \n",
    "                    \n",
    "                    sampling_interval = np.diff(pot).mean()\n",
    "                    new_interval = sampling_interval / config['interpolation_factor']\n",
    "                    pot_interp = np.arange(0, pot[-1], new_interval)\n",
    "                    \n",
    "                    for cell_name, cell_data in data_dict['cells_data'].items():\n",
    "                        psph = cell_data['psph'].flatten()\n",
    "                        pspt = cell_data['pspt'].flatten()\n",
    "                        spike_phase = cell_data['spike_phase'].flatten()\n",
    "                        pval = cell_data['pval'][0][0]\n",
    "                        hd_mean = cell_data['hd_mean'][0][0]\n",
    "                        hd_std = cell_data['hd_std'][0][0]\n",
    "                        tune_width = cell_data['tune_width'][0][0]\n",
    "                        autocorrelogram = cell_data['autocorrelogram']\n",
    "                        intrinsic_freq = cell_data['intrinsic_freq'][0][0]\n",
    "                        cell_type = cell_data['cell_type']\n",
    "                        \n",
    "                        #get the spike moving direction called pspm, using the pspt and the calculated ppom\n",
    "                        pspm = get_spike_direction(ppom, pot, pspt)\n",
    "                        \n",
    "                        #get the spike time when the difference between ppom and ppoh is more than 30 degree\n",
    "                        pspt_diff = get_spike_times_large_diff(ppom, ppoh, pot, pspt, threshold=60)\n",
    "                        psph_diff = get_spike_direction(ppoh.flatten(), pot, pspt_diff)\n",
    "                        pspm_diff = get_spike_direction(ppom, pot, pspt_diff)\n",
    "                        \n",
    "                        #store matname for each cell\n",
    "                        matnames[cell_name] = [ratname, file_path]\n",
    "                        \n",
    "                            \n",
    "                        try:\n",
    "                            #plot\n",
    "                            fig = plt.figure(figsize=(4,3))\n",
    "                            gs=fig.add_gridspec(2, 3, width_ratios=[1, 2, 1])\n",
    "                            \n",
    "                            #plot head direction tuning map\n",
    "                            ax0 = fig.add_subplot(gs[0, 0], projection='polar')\n",
    "                            ax0 = plot_head_direction_tuning(ax0, ppoh, psph, config)\n",
    "                            ax0.set_title(np.round(pval,3))\n",
    "                            \n",
    "                            #plot spike phase versus head direction, i.e., check phase precession\n",
    "                            ax2 = fig.add_subplot(gs[0, 1])\n",
    "                            spike_array = compute_spike_array(pspt, pot_interp)\n",
    "                            autocorrelogram2 = compute_autocorrelation(spike_array, bin_size=new_interval, max_lag=0.5)                   \n",
    "                            ax2 = plot_autocorrelogram(ax2, autocorrelogram2, cell_type)\n",
    "                            \n",
    "                            #plot phase precession\n",
    "                            ax3 =  fig.add_subplot(gs[0, 2], projection='polar')\n",
    "                            #plot moving direction tuning map\n",
    "                            ax3 = plot_head_direction_tuning(ax3, ppom, pspm, config)\n",
    "                            \n",
    "                            ax4 = fig.add_subplot(gs[1, 0], projection='polar')\n",
    "                            #plot head direction tuning map with difference spike time\n",
    "                            ax4 = plot_head_direction_tuning(ax4, ppoh, psph_diff, config)\n",
    "\n",
    "                            ax5  = fig.add_subplot(gs[1, 2], projection='polar')\n",
    "                            #plot moving direction tuning map with difference spike time\n",
    "                            ax5 = plot_head_direction_tuning(ax5, ppom, pspm_diff, config)\n",
    "                            \n",
    "                            output_path = os.path.join(output_dir, f\"{cell_name}.png\")\n",
    "                            plt.tight_layout()\n",
    "                            plt.savefig(output_path)\n",
    "                            \n",
    "                            #save tuning width\n",
    "                            all_tw.append(tune_width)\n",
    "                        \n",
    "                            #save fig according to cell type in different folders\n",
    "                            if 'ThetaxHD' in cell_type:\n",
    "                                \n",
    "                                #save tuning width\n",
    "                                theta_tw.append(tune_width)\n",
    "                                                                    \n",
    "                                if 'skip'in cell_type:\n",
    "                                    #save tuning width\n",
    "                                    theta_skip_tw.append(tune_width)\n",
    "                                    output_skip_path = os.path.join(output_skip_dir, f\"{cell_name}.png\")\n",
    "                                    plt.savefig(output_skip_path)\n",
    "                                elif 'ThetaxHD' in cell_type:\n",
    "                                    #save tuning width\n",
    "                                    theta_nonskip_tw.append(tune_width)\n",
    "                                    output_nonskip_path = os.path.join(output_nonskip_dir, f\"{cell_name}.png\")\n",
    "                                    plt.savefig(output_nonskip_path)\n",
    "                            elif 'HDC' in cell_type:\n",
    "                                nontheta_tw.append(tune_width)\n",
    "                                output_nontheta_path = os.path.join(output_nontheta_dir, f\"{cell_name}.png\")\n",
    "                                plt.savefig(output_nontheta_path)\n",
    "                                \n",
    "                            plt.close(fig)\n",
    "                            \n",
    "                            total_cells += 1\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error processing {cell_name}: {e}\")\n",
    "                        \n",
    "print(f\"Total number of HD cells processed: {total_cells}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anticipative_track",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
